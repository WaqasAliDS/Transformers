{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x7qA4Hsf0wKO"
   },
   "source": [
    "# Hugging Face Transformers\n",
    "The Hugging Face Transformers library provides a vast collection of state-of-the-art pre-trained models for various natural language processing (NLP) tasks. It simplifies the process of implementing these models by offering an intuitive API, allowing developers and researchers to focus on building applications rather than dealing with the intricacies of model training and architecture. With support for tasks like text classification, named entity recognition, question answering, summarization, and zero-shot classification, Hugging Face Transformers enables users to leverage powerful models with minimal effort.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FYC--89sxXvE"
   },
   "outputs": [],
   "source": [
    "#packages\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MK1NSiQz6tBw"
   },
   "source": [
    "This package provides the core functionality for working with pre-trained models and pipelines. The pipeline function allows users to easily instantiate a model for a specific NLP task without needing to manage the complexities of the model architecture or training process. By specifying the task type, users can quickly access a variety of models tailored for their needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "INgfYZbUykWY"
   },
   "source": [
    "# Text Classifiication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWNuNDtp5avI"
   },
   "source": [
    "1. **Text Classification Model**: [nlptown/bert-base-multilingual-uncased-sentiment](https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment)\n",
    "   - **Description**: This model performs sentiment analysis by classifying input text into sentiment categories such as positive, negative, or neutral. It is based on the BERT architecture and is fine-tuned for multilingual support, making it suitable for various languages.\n",
    "   - **Usage**: Ideal for applications that require understanding user sentiment from feedback, reviews, or social media posts.\n",
    "   - **Output Example**: For an input like `\"I'm feeling great today!\"`, the output will look like:\n",
    "     ```json\n",
    "     [{\"label\": \"5 stars\", \"score\": 0.85}]\n",
    "     ```\n",
    "     This indicates a strong positive sentiment, with a score reflecting the model's confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZcqXmaKRxnu3",
    "outputId": "f8c8187b-8b61-4b74-d632-151061b65c8b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Text Classification with a different model\n",
    "# Using a sentiment analysis model for classification\n",
    "pipe = pipeline(task=\"text-classification\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dS84uzhWxnxZ",
    "outputId": "73a73f91-f894-47af-c8ec-998ed966ddf2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Classification Results:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': '5 stars', 'score': 0.7518251538276672}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run pipe with a single string\n",
    "result1 = pipe(\"I'm feeling great today!\")\n",
    "# Display results\n",
    "print(\"Text Classification Results:\")\n",
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N52irPOjxnz-",
    "outputId": "9e3bae63-61de-446a-a67d-82eeca18ba65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Classification Results:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': '5 stars', 'score': 0.8564531207084656},\n",
       " {'label': '2 stars', 'score': 0.4690088629722595}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run pipe with a list of strings\n",
    "result2 = pipe([\"I love programming!\", \"I'm really upset with the weather.\"])# Display results\n",
    "print(\"Text Classification Results:\")\n",
    "result2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ZL9nHV2zkpp"
   },
   "source": [
    "# Name Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3gKGeF875oWH"
   },
   "source": [
    "2. **Named Entity Recognition Model**: [dbmdz/bert-large-cased-finetuned-conll03-english](https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english)\n",
    "   - **Description**: This model identifies and classifies named entities within text, including organizations, people, dates, and locations. It is fine-tuned on the CoNLL-03 dataset, which is a benchmark for NER tasks.\n",
    "   - **Usage**: Useful for extracting important information from unstructured text data, such as news articles or reports.\n",
    "   - **Output Example**: For the input `\"Microsoft was founded by Bill Gates and Paul Allen in 1975 in Albuquerque.\"`, the output will look like:\n",
    "     ```json\n",
    "     [\n",
    "       {\"word\": \"Microsoft\", \"score\": 0.99, \"entity\": \"B-ORG\"},\n",
    "       {\"word\": \"Bill Gates\", \"score\": 0.98, \"entity\": \"B-PER\"},\n",
    "       {\"word\": \"Paul Allen\", \"score\": 0.97, \"entity\": \"B-PER\"},\n",
    "       {\"word\": \"1975\", \"score\": 0.96, \"entity\": \"B-DATE\"},\n",
    "       {\"word\": \"Albuquerque\", \"score\": 0.95, \"entity\": \"B-LOC\"}\n",
    "     ]\n",
    "     ```\n",
    "     This output provides the recognized entities along with their types and confidence scores.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6tS8W8fmxn5c",
    "outputId": "e80a9241-4b3a-4a45-d722-135f3f273cd4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Named Entity Recognition with a different model\n",
    "# Using a fine-tuned NER model\n",
    "ner_pipe = pipeline(task=\"ner\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "iTIV2WJJ15fH"
   },
   "outputs": [],
   "source": [
    "ner_result = ner_pipe(\"Microsoft was founded by Bill Gates and Paul Allen in 1975 in Albuquerque.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lqp9oDud15ii",
    "outputId": "a1a3bd51-affe-4934-9162-028a33cac250"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named Entity Recognition Results:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity': 'I-ORG',\n",
       "  'score': 0.99945015,\n",
       "  'index': 1,\n",
       "  'word': 'Microsoft',\n",
       "  'start': 0,\n",
       "  'end': 9},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.99527526,\n",
       "  'index': 5,\n",
       "  'word': 'Bill',\n",
       "  'start': 25,\n",
       "  'end': 29},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.99724114,\n",
       "  'index': 6,\n",
       "  'word': 'Gates',\n",
       "  'start': 30,\n",
       "  'end': 35},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.99846363,\n",
       "  'index': 8,\n",
       "  'word': 'Paul',\n",
       "  'start': 40,\n",
       "  'end': 44},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.99925965,\n",
       "  'index': 9,\n",
       "  'word': 'Allen',\n",
       "  'start': 45,\n",
       "  'end': 50},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.99683386,\n",
       "  'index': 13,\n",
       "  'word': 'Albuquerque',\n",
       "  'start': 62,\n",
       "  'end': 73}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Named Entity Recognition Results:\")\n",
    "ner_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lks4spJRzsfu"
   },
   "source": [
    "# Question - Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ztAi5c195y5a"
   },
   "source": [
    "3. **Question Answering Model**: [distilbert-base-uncased-distilled-squad](https://huggingface.co/distilbert-base-uncased-distilled-squad)\n",
    "   - **Description**: This model answers questions based on a provided context. It is a distilled version of BERT, optimized for faster inference while maintaining accuracy. It is specifically trained on the SQuAD (Stanford Question Answering Dataset).\n",
    "   - **Usage**: Suitable for building chatbots, search engines, or any application where automated question answering is needed.\n",
    "   - **Output Example**: For the context `\"The Eiffel Tower is located in Paris, France.\"` and the question `\"Where is the Eiffel Tower?\"`, the output will look like:\n",
    "     ```json\n",
    "     {\"answer\": \"Paris, France\", \"score\": 0.95, \"start\": 28, \"end\": 42}\n",
    "     ```\n",
    "     This indicates the answer found in the context, along with its confidence score and the character indices of the answer in the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NeyoK45g1SjT",
    "outputId": "0f871f12-cf15-4ac4-ac70-ff9142502d20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question Answering Result:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.8541361093521118,\n",
       " 'start': 31,\n",
       " 'end': 44,\n",
       " 'answer': 'Paris, France'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question Answering with a different context\n",
    "qa_pipe = pipeline(task=\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\")\n",
    "qa_result = qa_pipe(context=\"The Eiffel Tower is located in Paris, France.\", question=\"Where is the Eiffel Tower?\")\n",
    "print(\"Question Answering Result:\")\n",
    "qa_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DXjBiYzO0Qp4"
   },
   "source": [
    "# Text Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WcXvyF9A55AM"
   },
   "source": [
    "4. **Text Summarization Model**: [facebook/bart-large-cnn](https://huggingface.co/facebook/bart-large-cnn)\n",
    "   - **Description**: This model generates concise summaries from longer texts while preserving the main ideas. It uses a sequence-to-sequence architecture that combines the strengths of both BERT and GPT models. The `facebook/bart-large-cnn` variant is fine-tuned for summarization tasks.\n",
    "   - **Usage**: Great for applications requiring summarization of articles, reports, or lengthy documents for quick understanding.\n",
    "   - **Output Example**: For the provided article about Hugging Face, the output may look like:\n",
    "     ```json\n",
    "     \"Hugging Face, founded in 2016, has become a leader in Natural Language Processing, enabling collaboration and code sharing.\"\n",
    "     ```\n",
    "     This provides a concise summary, highlighting the key information from the input text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "lRqJj9k80NfZ"
   },
   "outputs": [],
   "source": [
    "# Text Summarization with a different model\n",
    "summarization_pipe = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ke33Jo4p0YOG"
   },
   "outputs": [],
   "source": [
    "summary_article = \"\"\"Hugging Face has transformed how the machine learning community collaborates and shares code.\n",
    "Founded in 2016, it quickly became a leader in Natural Language Processing, allowing researchers and developers\n",
    "to share models and datasets. The platform has grown rapidly, attracting investment and expanding its offerings,\n",
    "including training, deployment, and user-friendly tools for various applications.\"\"\"\n",
    "summary_result = summarization_pipe(summary_article, min_length=30, max_length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RCmDLxYp2XkL",
    "outputId": "e7d271ae-54ea-46ba-d45c-026c1907994c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Summarization Result:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'Hugging Face has transformed how the machine learning community collaborates and shares code. The platform has grown rapidly, attracting investment and expanding its offerings,  including training, deployment, and user-friendly tools.'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Text Summarization Result:\")\n",
    "summary_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kCTooP34zzxz"
   },
   "source": [
    "# Zero Shot Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ikehUMj6GXA"
   },
   "source": [
    "5. **Zero-Shot Classification Model**: [facebook/bart-large-mnli](https://huggingface.co/facebook/bart-large-mnli)\n",
    "   - **Description**: This model performs classification tasks without requiring specific training for the labels involved. It uses the natural language inference (NLI) task to determine the most appropriate labels for given text, allowing for flexible classification.\n",
    "   - **Usage**: Ideal for scenarios where predefined categories may change frequently, such as content moderation or topic classification in dynamic environments.\n",
    "   - **Output Example**: For input `\"The quick brown fox jumps over the lazy dog.\"` and candidate labels `[\"literature\", \"animals\", \"philosophy\"]`, the output may look like:\n",
    "     ```json\n",
    "     {\n",
    "       \"sequence\": \"The quick brown fox jumps over the lazy dog.\",\n",
    "       \"labels\": [\"animals\", \"literature\", \"philosophy\"],\n",
    "       \"scores\": [0.92, 0.05, 0.03]\n",
    "     }\n",
    "     ```\n",
    "     This indicates that the text is classified as belonging to the \"animals\" category with high confidence, followed by lower confidence scores for other labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "TgqcGMu4167q"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "zero_shot_classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "documents = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"To be or not to be, that is the question.\",\n",
    "    \"A journey of a thousand miles begins with a single step.\"\n",
    "]\n",
    "candidate_labels = [\"literature\", \"animals\", \"philosophy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "8CBsdeMV3QDp"
   },
   "outputs": [],
   "source": [
    "# Classify documents\n",
    "zero_shot_results = zero_shot_classifier(documents, candidate_labels=candidate_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8-WmtZlT36tq",
    "outputId": "6e7d63ae-35db-4ab2-9205-dc8c86d8bf7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-Shot Classification Results:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'The quick brown fox jumps over the lazy dog.',\n",
       "  'labels': ['animals', 'literature', 'philosophy'],\n",
       "  'scores': [0.9911988973617554, 0.005967895500361919, 0.0028331829234957695]},\n",
       " {'sequence': 'To be or not to be, that is the question.',\n",
       "  'labels': ['philosophy', 'literature', 'animals'],\n",
       "  'scores': [0.7825393676757812, 0.1451304852962494, 0.07233018428087234]},\n",
       " {'sequence': 'A journey of a thousand miles begins with a single step.',\n",
       "  'labels': ['philosophy', 'literature', 'animals'],\n",
       "  'scores': [0.5001646876335144, 0.27931058406829834, 0.22052477300167084]}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Zero-Shot Classification Results:\")\n",
    "zero_shot_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "RzPGIptK3P6Q"
   },
   "outputs": [],
   "source": [
    "# Flagging multiple labels\n",
    "multi_label_result1 = zero_shot_classifier(documents[0], candidate_labels=candidate_labels, multi_label=True)\n",
    "multi_label_result2 = zero_shot_classifier(documents[1], candidate_labels=candidate_labels, multi_label=True)\n",
    "multi_label_result3 = zero_shot_classifier(documents[2], candidate_labels=candidate_labels, multi_label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LqBKCK2O3p9Z",
    "outputId": "bbbc373d-c41e-430b-811b-9021db22f7c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flagging Multiple Labels:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'The quick brown fox jumps over the lazy dog.',\n",
       " 'labels': ['animals', 'literature', 'philosophy'],\n",
       " 'scores': [0.9961634278297424, 0.027642544358968735, 0.0013539043720811605]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Flagging Multiple Labels:\")\n",
    "multi_label_result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nIDOyW9T33yU",
    "outputId": "bd0728f2-15b5-4828-be18-09de8a76f685"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'To be or not to be, that is the question.',\n",
       " 'labels': ['philosophy', 'literature', 'animals'],\n",
       " 'scores': [0.814192533493042, 0.11284735053777695, 0.011561857536435127]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_label_result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B5x4rGA7331y",
    "outputId": "6118ea11-2afd-46a3-f7b7-f7a1143c90df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'A journey of a thousand miles begins with a single step.',\n",
       " 'labels': ['philosophy', 'literature', 'animals'],\n",
       " 'scores': [0.3544122278690338, 0.045395947992801666, 0.016817163676023483]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_label_result3"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
